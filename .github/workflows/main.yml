name: Deploy to EKS with Karpenter

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
      ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
      EKS_CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME }}
      EKS_ROLE_ARN: ${{ secrets.EKS_ROLE_ARN }}
      KARPENTER_VERSION: "1.6.0"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.EKS_ROLE_ARN }}
          role-skip-session-tagging: true

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push Docker image
        run: |
          docker build -t project/flask:latest .
          docker tag project/flask:latest 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:latest
          docker push 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:latest

      - name: Install aws-iam-authenticator
        run: |
          curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.6.14/aws-iam-authenticator_0.6.14_linux_amd64
          chmod +x ./aws-iam-authenticator
          sudo mv ./aws-iam-authenticator /usr/local/bin

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
            version: 'latest'

      # kubeconfig 완전 재설정
      - name: Update Kubeconfig
        run: |
          echo "==== 클러스터 정보 확인 ===="
          aws eks describe-cluster --region $AWS_REGION --name $EKS_CLUSTER_NAME --query 'cluster.{Name:name,Status:status,Endpoint:endpoint}'
          
          echo "=== 기존 kubeconfig 정리 ==="
          rm -f ~/.kube/config
          mkdir -p ~/.kube
          
          echo "=== 새로운 kubeconfig 생성 ==="
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME --verbose
          
          echo "=== kubeconfig 파일 권한 설정 ==="
          chmod 600 ~/.kube/config
          
          echo "=== kubeconfig 내용 확인 ==="
          kubectl config view --minify
          
          echo "=== 현재 컨텍스트 확인 ==="
          kubectl config current-context
          
          echo "=== 엔드포인트 확인 ==="
          kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}'
          echo

      # 강화된 kubectl 접근 테스트
      - name: Verify kubectl access
        run: |
          echo "=== Current AWS Identity ==="
          aws sts get-caller-identity
          
          echo "=== kubectl 버전 확인 ==="
          kubectl version --client
          
          echo "=== 클러스터 연결 테스트 ==="
          kubectl cluster-info
          
          echo "=== 권한 테스트 ==="
          kubectl auth can-i get pods --all-namespaces || echo "Pod access check failed"
          kubectl auth can-i get namespaces || echo "Namespace access check failed"
          kubectl auth can-i get nodes || echo "Node access check failed"
          
          echo "=== 네임스페이스 목록 ==="
          kubectl get namespaces || echo "Failed to get namespaces"
          
          echo "=== 노드 목록 ==="
          kubectl get nodes || echo "Failed to get nodes"

# 기존 ECR에 Karpenter 이미지 추가
      - name: Add Karpenter image to existing ECR
        run: |
          echo "=== 기존 project/flask ECR에 Karpenter 이미지 추가 ==="
          
          # GitHub Actions 러너에서 ECR Public 이미지 다운로드 (퍼블릭 네트워크 사용)
          echo "Karpenter 이미지 다운로드 중..."
          docker pull public.ecr.aws/karpenter/controller:v0.34.0
          
          # 기존 Flask ECR에 karpenter 태그로 저장
          echo "기존 ECR에 태그 및 푸시..."
          docker tag public.ecr.aws/karpenter/controller:v0.34.0 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:karpenter-0.34.0
          docker push 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:karpenter-0.34.0
          
          echo "✅ Karpenter 이미지가 기존 ECR에 추가되었습니다!"
          
          # 추가된 이미지 확인
          aws ecr describe-images --repository-name project/flask --region ap-northeast-2 --query 'imageDetails[*].imageTags'

      # Karpenter 설치 (기존 ECR 이미지 사용)
      - name: Install Karpenter with existing ECR
        run: |
          echo "=== 기존 ECR 이미지로 Karpenter 설치 ==="
          
          # 기존 정리
          helm uninstall karpenter -n karpenter 2>/dev/null || echo "No existing release"
          kubectl delete namespace karpenter --ignore-not-found=true
          sleep 30
          
          # Karpenter 설정
          kubectl create namespace karpenter
          
          # ServiceAccount 생성 (기존 project-node-group 역할 사용)
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: karpenter
            namespace: karpenter
            annotations:
              eks.amazonaws.com/role-arn: arn:aws:iam::574205320701:role/project-node-group
          EOF
          
          # 인스턴스 프로파일 설정
          aws iam create-instance-profile --instance-profile-name KarpenterNodeInstanceProfile 2>/dev/null || echo "Instance profile already exists"
          aws iam add-role-to-instance-profile --instance-profile-name KarpenterNodeInstanceProfile --role-name project-node-group 2>/dev/null || echo "Role already added"
          
          # 기존 ECR 이미지로 Karpenter 설치
          echo "Helm으로 Karpenter 설치 중..."
          helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
            --version $KARPENTER_VERSION \
            --namespace karpenter \
            --set "settings.clusterName=$EKS_CLUSTER_NAME" \
            --set "settings.clusterEndpoint=$(aws eks describe-cluster --region $AWS_REGION --name $EKS_CLUSTER_NAME --query 'cluster.endpoint' --output text)" \
            --set "serviceAccount.create=false" \
            --set "serviceAccount.name=karpenter" \
            --set controller.image.repository=574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask \
            --set controller.image.tag=karpenter-0.34.0 \
            --set controller.image.digest=sha256:4263bb55b891c19896e1f6d70a993d242a465be01bebaa743199c26c3803d41b \
            --set controller.resources.requests.cpu=200m \
            --set controller.resources.requests.memory=200Mi \
            --set controller.resources.limits.cpu=400m \
            --set controller.resources.limits.memory=400Mi \
            --set controller.replicas=1 \
            --timeout 8m0s
          
          echo "=== 설치 완료! ==="

      # Karpenter 상태 확인 및 준비 대기
      - name: Verify Karpenter installation
        run: |
          echo "=== Karpenter 설치 확인 ==="
          
          # 설치 후 잠시 대기
          sleep 60
          
          # Pod 상태 확인
          echo "Pod 상태:"
          kubectl get pods -n karpenter -o wide
          
          # Pod이 Running 상태가 될 때까지 대기 (최대 10분)
          echo "=== Karpenter Pod 준비 대기 ==="
          for i in {1..20}; do
            echo "상태 확인 $i/20..."
            
            if kubectl get pods -n karpenter --field-selector=status.phase=Running 2>/dev/null | grep -q "Running"; then
              echo "✅ Karpenter Pod이 Running 상태입니다!"
              break
            fi
            
            # 중간 진단
            if [[ $i -eq 10 ]]; then
              echo "=== 중간 상태 진단 ==="
              kubectl describe pods -n karpenter | tail -30
            fi
            
            sleep 30
          done
          
          # CRD 확인
          echo "=== CRD 대기 및 확인 ==="
          for i in {1..10}; do
            if kubectl get crd nodepools.karpenter.sh 2>/dev/null; then
              echo "✅ NodePool CRD 준비 완료!"
              break
            fi
            echo "CRD 대기 중... ($i/10)"
            sleep 20
          done
          
          # 최종 상태 설정
          echo "=== 최종 결과 ==="
          if kubectl get pods -n karpenter --field-selector=status.phase=Running 2>/dev/null | grep -q "Running" && kubectl get crd nodepools.karpenter.sh 2>/dev/null; then
            echo "KARPENTER_READY=true" >> $GITHUB_ENV
            echo "🎉 Karpenter 설치 및 준비 완료!"
            echo "사용된 이미지: 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:karpenter-1.6.0"
            kubectl get pods -n karpenter
            kubectl get crd | grep karpenter
          else
            echo "KARPENTER_READY=false" >> $GITHUB_ENV
            echo "❌ Karpenter 설치 실패"
            echo "Pod 상태:"
            kubectl get pods -n kube-system
            kubectl describe pods -n karpenter | grep -A 10 "Events:" || echo "이벤트 없음"
          fi
          
      - name: Apply Karpenter NodePool configuration
        run: |
            echo "=== NodePool 적용 ==="
            cat <<EOF | kubectl apply -f -
            apiVersion: karpenter.sh/v1beta1
            kind: NodePool
            metadata:
              name: default
            spec:
              template:
                metadata:
                  labels:
                    karpenter.sh/nodepool: default
                spec:
                  requirements:
                    - key: kubernetes.io/arch
                      operator: In
                      values: ["amd64"]
                    - key: kubernetes.io/os
                      operator: In
                      values: ["linux"]
                    - key: karpenter.sh/capacity-type
                      operator: In
                      values: ["spot", "on-demand"]
                    - key: node.kubernetes.io/instance-type
                      operator: In
                      values: ["t3.medium", "t3.large", "t3.xlarge", "m5.large", "m5.xlarge"]
                  
                  nodeClassRef:
                    apiVersion: karpenter.k8s.aws/v1beta1
                    kind: EC2NodeClass
                    name: default
              
              limits:
                cpu: 1000
                memory: 1000Gi
              
              disruption:
                consolidationPolicy: WhenUnderutilized
                consolidateAfter: 30s
                expireAfter: 30m
            EOF
  
      - name: Apply Karpenter EC2NodeClass configuration
        run: |
            echo "=== EC2NodeClass 적용 ==="
            cat <<EOF | kubectl apply -f -
            apiVersion: karpenter.k8s.aws/v1beta1
            kind: EC2NodeClass
            metadata:
              name: default
            spec:
              amiFamily: AL2023
              
              # 실제 서브넷 ID 직접 지정
              subnetSelectorTerms:
                - id: subnet-05debc08a249d8c0d
                - id: subnet-0005ba7fed0b87805
              
              # 실제 보안 그룹 ID 직접 지정
              securityGroupSelectorTerms:
                - id: sg-0f6bacca39650f9e6
              
              role: "KarpenterNodeInstanceProfile"
              
              userData: |
                #!/bin/bash
                /etc/eks/bootstrap.sh $EKS_CLUSTER_NAME
                echo "Node bootstrapped successfully"
              
              blockDeviceMappings:
                - deviceName: /dev/xvda
                  ebs:
                    volumeSize: 20Gi
                    volumeType: gp3
                    encrypted: true
                    deleteOnTermination: true
              
              tags:
                Environment: production
                Team: platform
                Project: flask-app
                karpenter.sh/discovery: $EKS_CLUSTER_NAME
            EOF

      - name: Set secrets for Kubernetes
        run: |
          kubectl delete secret flask-secrets --ignore-not-found
          kubectl create secret generic flask-secrets \
            --from-literal=GEMINI_API_KEY="${{ secrets.GEMINI_API_KEY }}" \
            --from-literal=TAGO_API_KEY="${{ secrets.TAGO_API_KEY }}" \
            --from-literal=API_KEY="${{ secrets.API_KEY }}" \
            --from-literal=FLASK_SECRET_KEY="${{ secrets.FLASK_SECRET_KEY }}" \
            --from-literal=MYSQL_URI="${{ secrets.MYSQL_URI }}" \
            --from-literal=AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --from-literal=AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            --from-literal=AWS_REGION="${{ secrets.AWS_REGION }}" \
            --from-literal=S3_BUCKET="${{ secrets.S3_BUCKET }}" \
            --from-literal=DYNAMODB_TABLE="${{ secrets.DYNAMODB_TABLE }}"

      - name: Deploy to EKS
        run: |
          kubectl apply -f deployment.yaml
          kubectl apply -f service.yaml

      - name: Wait for deployment to be ready
        run: |
          echo "Waiting for deployment to be ready..."
          kubectl rollout status deployment/flask-app --timeout=300s

      - name: Check Karpenter node provisioning
        run: |
          echo "=== Karpenter Status ==="
          kubectl get nodepool
          kubectl get ec2nodeclass
          kubectl get pods -n karpenter
          echo "=== Node Status ==="
          kubectl get nodes -L karpenter.sh/nodepool
          echo "=== Pending Pods ==="
          kubectl get pods --field-selector=status.phase=Pending

      - name: Wait for LoadBalancer DNS
        id: wait-lb
        run: |
          for i in {1..30}; do
            LB_DNS=$(kubectl get svc flask-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            if [ -n "$LB_DNS" ]; then
              echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
              echo "LoadBalancer DNS: $LB_DNS"
              break
            fi
            echo "Waiting for LoadBalancer DNS... ($i/30)"
            sleep 10
          done
          if [ -z "$LB_DNS" ]; then
            echo "LoadBalancer DNS not assigned after 5 minutes!"
            kubectl get svc flask-service -o yaml
            exit 1
          fi

      - name: Health check
        run: |
          echo "Waiting for service to be fully ready..."
          sleep 60
          echo "Running health check on http://$LB_DNS"
          python healthcheck.py http://$LB_DNS

      - name: Show deployment status
        run: |
          echo "=== Deployment Summary ==="
          echo "Application URL: http://$LB_DNS"
          echo "=== Pods Status ==="
          kubectl get pods -l app=flask-app
          echo "=== Service Status ==="
          kubectl get svc flask-service
          echo "=== Deployment Status ==="
          kubectl get deployment flask-app
          echo "=== Karpenter Nodes ==="
          kubectl get nodes -L karpenter.sh/nodepool,node.kubernetes.io/instance-type