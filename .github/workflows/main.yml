name: Deploy to EKS with Karpenter

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}
      ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
      EKS_CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME }}
      EKS_ROLE_ARN: ${{ secrets.EKS_ROLE_ARN }}
      KARPENTER_VERSION: "1.6.0"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.EKS_ROLE_ARN }}
          role-skip-session-tagging: true

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push Docker image
        run: |
          docker build -t project/flask:latest .
          docker tag project/flask:latest 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:latest
          docker push 574205320701.dkr.ecr.ap-northeast-2.amazonaws.com/project/flask:latest

      - name: Install aws-iam-authenticator
        run: |
          curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.6.14/aws-iam-authenticator_0.6.14_linux_amd64
          chmod +x ./aws-iam-authenticator
          sudo mv ./aws-iam-authenticator /usr/local/bin

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
            version: 'latest'

      # kubeconfig 완전 재설정
      - name: Update Kubeconfig
        run: |
          echo "=== 클러스터 정보 확인 ==="
          aws eks describe-cluster --region $AWS_REGION --name $EKS_CLUSTER_NAME --query 'cluster.{Name:name,Status:status,Endpoint:endpoint}'
          
          echo "=== 기존 kubeconfig 정리 ==="
          rm -f ~/.kube/config
          mkdir -p ~/.kube
          
          echo "=== 새로운 kubeconfig 생성 ==="
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME --verbose
          
          echo "=== kubeconfig 파일 권한 설정 ==="
          chmod 600 ~/.kube/config
          
          echo "=== kubeconfig 내용 확인 ==="
          kubectl config view --minify
          
          echo "=== 현재 컨텍스트 확인 ==="
          kubectl config current-context
          
          echo "=== 엔드포인트 확인 ==="
          kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}'
          echo

      # 강화된 kubectl 접근 테스트
      - name: Verify kubectl access
        run: |
          echo "=== Current AWS Identity ==="
          aws sts get-caller-identity
          
          echo "=== kubectl 버전 확인 ==="
          kubectl version --client
          
          echo "=== 클러스터 연결 테스트 ==="
          kubectl cluster-info
          
          echo "=== 권한 테스트 ==="
          kubectl auth can-i get pods --all-namespaces || echo "Pod access check failed"
          kubectl auth can-i get namespaces || echo "Namespace access check failed"
          kubectl auth can-i get nodes || echo "Node access check failed"
          
          echo "=== 네임스페이스 목록 ==="
          kubectl get namespaces || echo "Failed to get namespaces"
          
          echo "=== 노드 목록 ==="
          kubectl get nodes || echo "Failed to get nodes"

      - name: Setup Karpenter IAM
        run: |
            echo "=== Karpenter IAM 설정 ==="
            aws iam create-instance-profile --instance-profile-name KarpenterNodeInstanceProfile 2>/dev/null || echo "Instance profile already exists"
            aws iam add-role-to-instance-profile --instance-profile-name KarpenterNodeInstanceProfile --role-name project-node-group 2>/dev/null || echo "Role already added"
            echo "Karpenter IAM 설정 완료"
  
      - name: Add Karpenter tags to resources
        run: |
            echo "=== Karpenter 태그 추가 ==="
            # 서브넷에 Karpenter 태그 추가
            aws ec2 create-tags --resources subnet-05debc08a249d8c0d subnet-0005ba7fed0b87805 \
              --tags Key=karpenter.sh/discovery,Value=$EKS_CLUSTER_NAME
            
            # 보안 그룹에 Karpenter 태그 추가  
            aws ec2 create-tags --resources sg-0f6bacca39650f9e6 \
              --tags Key=karpenter.sh/discovery,Value=$EKS_CLUSTER_NAME
            
            echo "태그 추가 완료"
  
      - name: Check if Karpenter is installed
        id: check-karpenter
        run: |
            if kubectl get deployment karpenter -n karpenter 2>/dev/null && kubectl get pods -n karpenter --field-selector=status.phase=Running 2>/dev/null | grep -q "2/2"; then
              echo "karpenter_installed=true" >> $GITHUB_OUTPUT
              echo "Karpenter is properly installed and running"
            else
              echo "karpenter_installed=false" >> $GITHUB_OUTPUT
              echo "Karpenter is not properly installed"
            fi
  
      - name: Clean and Install Karpenter
        if: steps.check-karpenter.outputs.karpenter_installed == 'false'
        run: |
            echo "=== Karpenter 정리 및 설치 ==="
            
            # 기존 Karpenter 완전 삭제
            helm uninstall karpenter -n karpenter 2>/dev/null || echo "No existing helm release"
            kubectl delete namespace karpenter --ignore-not-found=true
            
            # 잠시 대기
            sleep 30
            
            # 새로 설치
            kubectl create namespace karpenter
            
            echo "=== Karpenter 설치 시작 ==="
            helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
              --version $KARPENTER_VERSION \
              --namespace karpenter \
              --create-namespace \
              --set "settings.clusterName=$EKS_CLUSTER_NAME" \
              --set controller.resources.requests.cpu=500m \
              --set controller.resources.requests.memory=512Mi \
              --set controller.resources.limits.cpu=1 \
              --set controller.resources.limits.memory=1Gi \
              --wait \
              --timeout 15m0s
            
            echo "=== Karpenter 설치 완료 ==="
  
      - name: Wait for Karpenter to be ready
        run: |
            echo "=== Karpenter 준비 상태 대기 ==="
            
            # Pod이 Ready 상태가 될 때까지 대기
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=karpenter -n karpenter --timeout=300s
            
            # CRD 확인
            for i in {1..10}; do
              if kubectl get crd nodepools.karpenter.sh 2>/dev/null && kubectl get crd ec2nodeclasses.karpenter.k8s.aws 2>/dev/null; then
                echo "Karpenter CRDs are ready!"
                break
              fi
              echo "Waiting for CRDs... ($i/10)"
              sleep 30
            done
            
            # 최종 상태 확인
            echo "=== Karpenter 상태 확인 ==="
            kubectl get pods -n karpenter
            kubectl get crd | grep karpenter
  
      - name: Apply Karpenter NodePool configuration
        run: |
            echo "=== NodePool 적용 ==="
            cat <<EOF | kubectl apply -f -
            apiVersion: karpenter.sh/v1beta1
            kind: NodePool
            metadata:
              name: default
            spec:
              template:
                metadata:
                  labels:
                    karpenter.sh/nodepool: default
                spec:
                  requirements:
                    - key: kubernetes.io/arch
                      operator: In
                      values: ["amd64"]
                    - key: kubernetes.io/os
                      operator: In
                      values: ["linux"]
                    - key: karpenter.sh/capacity-type
                      operator: In
                      values: ["spot", "on-demand"]
                    - key: node.kubernetes.io/instance-type
                      operator: In
                      values: ["t3.medium", "t3.large", "t3.xlarge", "m5.large", "m5.xlarge"]
                  
                  nodeClassRef:
                    apiVersion: karpenter.k8s.aws/v1beta1
                    kind: EC2NodeClass
                    name: default
              
              limits:
                cpu: 1000
                memory: 1000Gi
              
              disruption:
                consolidationPolicy: WhenUnderutilized
                consolidateAfter: 30s
                expireAfter: 30m
            EOF
  
      - name: Apply Karpenter EC2NodeClass configuration
        run: |
            echo "=== EC2NodeClass 적용 ==="
            cat <<EOF | kubectl apply -f -
            apiVersion: karpenter.k8s.aws/v1beta1
            kind: EC2NodeClass
            metadata:
              name: default
            spec:
              amiFamily: AL2023
              
              # 실제 서브넷 ID 직접 지정
              subnetSelectorTerms:
                - id: subnet-05debc08a249d8c0d
                - id: subnet-0005ba7fed0b87805
              
              # 실제 보안 그룹 ID 직접 지정
              securityGroupSelectorTerms:
                - id: sg-0f6bacca39650f9e6
              
              role: "KarpenterNodeInstanceProfile"
              
              userData: |
                #!/bin/bash
                /etc/eks/bootstrap.sh $EKS_CLUSTER_NAME
                echo "Node bootstrapped successfully"
              
              blockDeviceMappings:
                - deviceName: /dev/xvda
                  ebs:
                    volumeSize: 20Gi
                    volumeType: gp3
                    encrypted: true
                    deleteOnTermination: true
              
              tags:
                Environment: production
                Team: platform
                Project: flask-app
                karpenter.sh/discovery: $EKS_CLUSTER_NAME
            EOF

      - name: Set secrets for Kubernetes
        run: |
          kubectl delete secret flask-secrets --ignore-not-found
          kubectl create secret generic flask-secrets \
            --from-literal=GEMINI_API_KEY="${{ secrets.GEMINI_API_KEY }}" \
            --from-literal=TAGO_API_KEY="${{ secrets.TAGO_API_KEY }}" \
            --from-literal=API_KEY="${{ secrets.API_KEY }}" \
            --from-literal=FLASK_SECRET_KEY="${{ secrets.FLASK_SECRET_KEY }}" \
            --from-literal=MYSQL_URI="${{ secrets.MYSQL_URI }}" \
            --from-literal=AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --from-literal=AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            --from-literal=AWS_REGION="${{ secrets.AWS_REGION }}" \
            --from-literal=S3_BUCKET="${{ secrets.S3_BUCKET }}" \
            --from-literal=DYNAMODB_TABLE="${{ secrets.DYNAMODB_TABLE }}"

      - name: Deploy to EKS
        run: |
          kubectl apply -f deployment.yaml
          kubectl apply -f service.yaml

      - name: Wait for deployment to be ready
        run: |
          echo "Waiting for deployment to be ready..."
          kubectl rollout status deployment/flask-app --timeout=300s

      - name: Check Karpenter node provisioning
        run: |
          echo "=== Karpenter Status ==="
          kubectl get nodepool
          kubectl get ec2nodeclass
          kubectl get pods -n karpenter
          echo "=== Node Status ==="
          kubectl get nodes -L karpenter.sh/nodepool
          echo "=== Pending Pods ==="
          kubectl get pods --field-selector=status.phase=Pending

      - name: Wait for LoadBalancer DNS
        id: wait-lb
        run: |
          for i in {1..30}; do
            LB_DNS=$(kubectl get svc flask-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            if [ -n "$LB_DNS" ]; then
              echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
              echo "LoadBalancer DNS: $LB_DNS"
              break
            fi
            echo "Waiting for LoadBalancer DNS... ($i/30)"
            sleep 10
          done
          if [ -z "$LB_DNS" ]; then
            echo "LoadBalancer DNS not assigned after 5 minutes!"
            kubectl get svc flask-service -o yaml
            exit 1
          fi

      - name: Health check
        run: |
          echo "Waiting for service to be fully ready..."
          sleep 60
          echo "Running health check on http://$LB_DNS"
          python healthcheck.py http://$LB_DNS

      - name: Show deployment status
        run: |
          echo "=== Deployment Summary ==="
          echo "Application URL: http://$LB_DNS"
          echo "=== Pods Status ==="
          kubectl get pods -l app=flask-app
          echo "=== Service Status ==="
          kubectl get svc flask-service
          echo "=== Deployment Status ==="
          kubectl get deployment flask-app
          echo "=== Karpenter Nodes ==="
          kubectl get nodes -L karpenter.sh/nodepool,node.kubernetes.io/instance-type